# https://dzone.com/articles/monitoring-docker-swarm
# https://github.com/stefanprodan/swarmprom/blob/master/prometheus/conf/prometheus.yml
# my global config

global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).
  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    monitor: "promswarm"
# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  - "swarm_node.rules.yml"
  - "swarm_task.rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]

  # - job_name: "dockerd-exporter"
  #   dns_sd_configs:
  #     - names:
  #         - "tasks.dockerd-exporter"
  #       type: "A"
  #       port: 9323

  - job_name: "node-exporter"
    dns_sd_configs:
      - names:
          - "tasks.node-exporter"
        type: "A"
        port: 9100

  - job_name: "cadvisor"
    dns_sd_configs:
      - names:
          - "tasks.cadvisor"
        type: "A"
        port: 8080

  - job_name: "traefik"

    # Override the global default and scrape targets from this job every 5 seconds.
    scrape_interval: 5s

    dns_sd_configs:
      - names:
          - "tasks.traefik"
        type: "A"
        port: 8080
